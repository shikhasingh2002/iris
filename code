import pandas as pd
import sklearn
from sklearn.datasets import load_boston
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn import svm
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import seaborn as sns


rf =RandomForestClassifier(random_state=1)
lr=LogisticRegression(random_state=1)
gbm=GradientBoostingClassifier(n_estimators=10)
dt=DecisionTreeClassifier(random_state=0)
sv=svm.SVC()
nn=MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(5,2),random_state=0)
df = pd.read_csv("C:/Users/shikha/OneDrive/Desktop/dataset/IRIS.csv")
'''
X_df = pd.read_csv("C:/Users/shikha/OneDrive/Desktop/dataset/IRIS.csv")
Y_df = pd.read_csv("C:/Users/shikha/OneDrive/Desktop/dataset/IRIS.csv")'''

X = df.drop(['species'], axis=1)
Y = df['species']



X_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state=1,test_size=10)
#print(Y_train)
train1 = rf.fit(X_train,Y_train)
Y_pred1=rf.predict(X_test)
print("Random Forest",accuracy_score(Y_test,Y_pred1))

train2 = lr.fit(X_train,Y_train)
Y_pred2=lr.predict(X_test)
print("Logistic Regression",accuracy_score(Y_test,Y_pred2))

train3 = gbm.fit(X_train,Y_train)
Y_pred3=gbm.predict(X_test)
print("GradientBoostingClassifier",accuracy_score(Y_test,Y_pred3))

train4 = dt.fit(X_train,Y_train)
Y_pred4=dt.predict(X_test)
print("decision tree",accuracy_score(Y_test,Y_pred4))

train5 = sv.fit(X_train,Y_train)
Y_pred5=sv.predict(X_test)
print("SVM",accuracy_score(Y_test,Y_pred5))

train6 = nn.fit(X_train,Y_train)
Y_pred6=nn.predict(X_test)
print("Neural Network",accuracy_score(Y_test,Y_pred6))

'''Output of the above code
Random Forest 1.0
Logistic Regression 1.0
GradientBoostingClassifier 1.0
decision tree 1.0
SVM 1.0
Neural Network 0.3'''
